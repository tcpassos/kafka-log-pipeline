filebeat.inputs:
# Input para logs SIGER normais
- type: filestream
  id: logs-siger-java
  enabled: true
  paths:
    - /usr/share/logs/SIGER_*_*_[0-9]*_[0-9]*_*.*
  scan_frequency: 30s
  close_inactive: 1m
  clean_inactive: 72h
  encoding: cp1252
  fields:
    topic: logs_java_siger
    client_id: ${CLIENT_ID}
  parsers:
    - multiline:
        pattern: '^[[:alnum:]]{4} [[:alnum:]]{6} [[:alnum:]]{6} \d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\s\w+\s+\S+\s(\s+|Caused by:|<)'
        negate: false
        match: after

# Input para logs SigerCrashReport
- type: filestream
  id: logs-sigercrash-java
  enabled: true
  paths:
    - /usr/share/logs/SigerCrashReport_*_*_[0-9]*_[0-9]*_*.*
  scan_frequency: 30s
  close_inactive: 1m
  clean_inactive: 72h
  encoding: cp1252
  fields:
    topic: logs_java_sigercrashreport
    client_id: ${CLIENT_ID}
  parsers:
    - multiline:
        pattern: '^[[:alnum:]]{4} [[:alnum:]]{6} [[:alnum:]]{6} \d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\s\w+\s+\S+\s(\s+|Caused by:|<)'
        negate: false
        match: after

# Desabilita a saída padrão para o Elasticsearch
output.elasticsearch:
  enabled: false

# Configura a saída para o Kafka com roteamento dinâmico por tópico
output.kafka:
  enabled: true
  hosts:
    - broker:29092
    - broker2:29092
  topic: '%{[fields.topic]}'
  key: '%{[log.file.path]}'
  required_acks: 1
